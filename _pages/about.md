---
layout: about
title: about
permalink: /
subtitle: <a href="https://wise.usc.edu/programs/grants-and-awards/faculty/wise-gabilan-assistant-professorship/">Gabilan</a> Assistant Professor â€¢ <a href="https://cs.usc.edu/">USC Viterbi CS</a> â€¢ Associate Director of USC <a href="https://cais.usc.edu/">Center for AI and Society</a> â€¢ <a href="https://nlp.usc.edu">USC NLP</a>

profile:
  align: right
  image: swabha_usc.jpeg
  image_circular: true # crops the image to make it circular


news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

My goal is to design frameworks that allow robust, and reliable frameworks that allow AI systems to be broadly and safely deployed, especially in applications with societal implications. Three directions that this corresponds to are:

- Safety-Critical, Robust and Reliable Frameworks for Evaluation:
  : What cannot be measured, cannot be improved. How can we reliably compare the generative capabilities of language models, and ensure our assessment is robust? How can we tell if performance match can translate to application safety, especially when there are societal implications? How can we evaluate new capabilities in LLMs when we do not necessarily know the correct answer?

- Understanding the Mechanisms that Drive Language Technologies:
  : Even the most reliable evaluation may not reveal much about the mechanisms driving powerful yet opaque models. What do model geometries reveal about the processes underlying our models, and how can we improve models through different designs? Are models by design limited to making some choices which can uniquely identify them?

- Human and AI Collaboration:
  : AI technologies are designed by humans and for humans, the future of AI involves cooperation and collaboration with humans. How can we say when a general-purpose model will reliably serve the custom utility for a human user? Where can these technologies complement human capabilities and where not?

These challenges require novel and creative techniques for redesigning generative evaluation to keep pace with model performance. This brings together a broad array of empirical research with theoretical fundamentals underlying language models.


<!-- I am an Assistant Professor of [Computer Science in the USC Viterbi School of Engineering](https://www.cs.usc.edu/), where I lead the [DILL Lab ðŸŒ¿](https://dill-lab.github.io/).
My research interests lie in the intersection of Natural Language Processing and Machine Learning, where I study language generation and generative evaluation, from a data-centric perspective.
I am newly appointed as an Associate Director of the [USC Center for AI and Society](https://cais.usc.edu/), where I additionally explore the impacts of language technologies on societal problems. -->

<!-- My research interests broadly span Natural Language Processing and Machine Learning, where I study the [estimation](https://arxiv.org/abs/2110.08420) of [dataset quality](https://arxiv.org/abs/2009.10795), the [(semi-)automatic](https://arxiv.org/abs/2201.05955) collection of impactful data, as well as [evaluating](https://arxiv.org/abs/2102.01454) how human biases [affect dataset construction](https://arxiv.org/abs/2111.07997) and model decisions. -->
<!-- via the [discovery](https://arxiv.org/abs/2103.01378) of [undesirable](https://arxiv.org/abs/2102.00086) [biases](https://arxiv.org/abs/1803.02324), including [social biases](https://arxiv.org/abs/2111.07997). The ultimate goal is advancing generalization not only via [bias reduction](https://arxiv.org/abs/2002.04108), but also via careful data curation, and [evaluation](https://arxiv.org/abs/2102.01454). -->


<!-- Previously, I was a postdoctoral investigator at the [Allen Institute for AI](https://allenai.org/) with [Yejin Choi](https://homes.cs.washington.edu/~yejin/).
I obtained my [PhD](/assets/pdf/swabha_thesis.pdf) from [Carnegie Mellon University](https://lti.cmu.edu/people/alumni/alumni-2019/swayamdipta-swabha.html), advised by [Noah Smith](https://nasmith.github.io/) and [Chris Dyer](http://www.cs.cmu.edu/~cdyer/).
During most of my PhD I was a visiting student at [UW](https://www.cs.washington.edu/).
I earned my MS from [Columbia University](https://www.cs.columbia.edu/), and my bachelors from [NIT Calicut](https://minerva.nitc.ac.in/) in India. -->


<!-- <hr/>

### [dill lab ðŸŒ¿](https://dill-lab.github.io/)


<span style="color:var(--global-theme-color-contrast);font-weight:bold">I am actively recruiting <a href="https://dill-lab.github.io/opportunities/"> PhD students</a> to the <a href="https://dill-lab.github.io/">DILL lab</a> this Fall.</span>

<hr/> -->
